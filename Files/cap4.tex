\phantomsection
\subsection*{Il \textit{profiling} come \textit{invisibility factor}}
\addcontentsline{toc}{subsection}{Il \textit{profiling} come \textit{invisibility factor}}

Il \textit{profiling} è forse l’esempio più interessante tra tutti quelli analizzati ed è quello che meglio descrive le nuove frontiere della tecnologia dell’informazione, ma è davvero qualcosa di negativo?
Ritornando al pensiero di Moor, tutto questo sviluppo, o inviluppo (secondo i punti di vista), tecnologico porta a una necessità di ampliare la \textit{computer ethics}. Il motivo principale riguarda tutte le branche dell’informatica. Un banale esempio, da tutti conosciuto, sono le intelligenze artificiali e la previsione che, in un futuro prossimo, possano arrivare ad avere una propria coscienza. La \textit{computer ethics}, però, è necessaria non solo in questi casi estremi. Essa è il fondamento di ogni tecnologia informatica che si è sviluppata in passato, si sta sviluppando nel presente e che si svilupperà in futuro. Quindi la necessità di ampliare la \textit{computer ethics} dipende solo da questo? No. La necessità di ampliarla è anche data dal fatto che, con lo sviluppo tecnologico e informatico, aumentano i casi di \textit{invisibility factor} e, spesso, essi non possono più essere organizzati tramite la classificazione creata da Moor nel suo documento del 1985.
Il \textit{profiling} rientra, per me, negli esempi di nuovi casi di \textit{invisibility factor}. 
Per spiegare il perché, bisogna innanzitutto capire: (1) se il \textit{profiling} sia davvero qualcosa di negativo, (2) come sia visto dalla \textit{computer ethics} e quindi intraprendere un discorso sull’importanza morale del commercio dei dati digitali e (3) se gli \textit{invisibility factor} siano sempre qualcosa di negativo oppure ci siano delle eccezioni.
Il \textit{profiling} è nato molto prima dello sviluppo delle tecnologie informatiche ed è tuttora utilizzato in diversi ambiti. In qualsiasi situazione esso venga utilizzato, lo scopo del \textit{profiling} è sempre lo stesso: inquadrare un individuo, ottenendo più informazioni possibili su di esso e studiarle creando un modello leggibile secondo gli standard ottenuti in precedenza, triangolando enormi quantità di dati, a loro volta prelevati da numerosi campioni.
Ciò che cambia da ambito ad ambito è la motivazione che porta a utilizzare la tecnica del \textit{profiling}. A seconda della motivazione, quindi, possiamo affermare se esso sia qualcosa di negativo o di positivo. Per esempio, il \textit{profiling} è molto utile per analizzare i dati di un paziente in campo medico, accostando i suoi dati ai dati dei modelli già presenti nel sistema.
È interessante soffermarsi un attimo su come la \textit{profilazione} in campo medico sia direttamente collegata alla big data analytics. 
I termini big data e big data analytics sono spesso usati nel contesto dell'assistenza sanitaria come una frase onnicomprensiva che si riferisce all'uso di grandi set di dati. Il loro uso sempre più regolare apre la strada a potenziali equivoci etici e sociali (Floridi 2012). I big data sono definiti come raccolte di dati così grandi e complesse che la loro manipolazione e gestione richiede l'applicazione di una serie di tecniche di calcolo, incluso ma non limitato all'apprendimento automatico e all'intelligenza artificiale (Stuart Ward e Barker 2013). L'analisi dei big data è definita come "il processo di raccolta, organizzazione e analisi di grandi insiemi di dati (chiamati big data) per scoprire pattern e altre informazioni utili" (Heymann e Rodier 2004).
Oppure si può fare riferimento alla \textit{profilazione} criminale: l'ultimo decennio ha visto l'emergere di tecniche di \textit{profiling} nelle forze dell'ordine per prevedere e prevenire futuri crimini prima che si verifichino.
Tutti esempi di situazioni in cui il \textit{profiling} ha solo aspetti positivi. Ma possiamo dire lo stesso riguardo al discorso morale? 
È giusto che vengano utilizzati i dati di un paziente, che non ha dato il consenso per il trattamento di essi, per salvare la vita di un altro paziente?
Per quanto riguarda il secondo esempio, invece, nel 2009, l'Istituto nazionale di giustizia ha negato queste tecniche di \textit{profiling} come polizie predittive, il che implica prelevare dati da fonti disparate, analizzarli e quindi utilizzare i risultati per anticipare, prevenire e rispondere più efficacemente ai reati futuri. Attualmente il software di sorveglianza predittiva è impiegato in 25 dipartimenti di polizia di grandi dimensioni nelle città degli Stati Uniti. Ad oggi esistono due tipi di software: sistemi basati sul luogo che fanno previsioni su dove e quando si verificherà un crimine futuro e strumenti basati sulle persone che prevedono chi è probabile che commetta o sia vittima di reato. Entrambi i sistemi si basano su algoritmi per generare le previsioni a partire dalla \textit{profilazione} e raccolta dati di crimini passati.
La crescente prevalenza della polizia predittiva è un sito contemporaneo di preoccupazione per una serie di organizzazioni per i diritti civili, attivisti e teorici. Nel loro recente lavoro su \textit{pre-crimine} e \textit{big data policing}, McCulloch e Wilson (2016) e Ferguson (2017) evidenziano i problemi che la polizia predittiva pone alle libertà civili sotto forma di sorveglianza rafforzata, discriminazione razziale e pregiudizio. Questi programmi, sostengono, si basano in modo problematico su dati di crimine storico, che sono spesso misure inaccurate dei passati tassi di criminalità, per colpire i luoghi e le persone di possibili reati futuri.
Il discorso è identico se ci spostiamo sulla \textit{profilazione} degli utenti di un social network. I loro dati possono anche essere venduti a società che li utilizzeranno per il bene comune, ma gli utenti stessi ne sono a conoscenza? Il discorso del commercio dei dati digitali è per la \textit{computer ethics} un argomento molto dibattuto e ad ora si può solamente affermare che la \textit{profilazione} sia sicuramente etica solo nel caso in cui l’utente (1) dia il proprio consenso al trattamento dei propri dati consapevolmente (spesso viene fatto inconsapevolmente), (2) sappia esattamente di quali dati si stia parlando, ma soprattutto (3) conosca chi potrebbe accedervi. Se viene a mancare anche solo uno di questi punti, allora si può parlare di \textit{invisibility factor}. 
Dato che è l’utente stesso ad aver fornito i dati, non c’è stato un accesso illegale, né tantomeno una violazione di proprietà privata. Per questo motivo questo \textit{invisibility factor} non può essere accostato all’abuso invisibile, ma è qualcosa di totalmente nuovo.
Altro esempio eclatante di nuovo \textit{invisibility factor} è l’utente che viene profilato e tramite gli algoritmi di \textit{profilazione} vengono ottenuti dati sensibili, o non, che non siano mai stati inseriti online né tantomeno autorizzati. Anche in questo caso non è avvenuto nessun “furto” in quanto i dati sono stati direttamente creati dall’algoritmo. Inoltre, numerosi casi hanno dimostrato che riuscire a dimostrare l’illegalità in questo tipo di \textit{profilazione} diventa quasi impossibile. 
Tutti questi sono esempi negativi di \textit{invisibility factor}, ma non sempre un \textit{invisibility factor} è qualcosa che danneggia l’utente.
Per esempio, i “valori di programmazione invisibili” (seconda categoria di \textit{invisibility factor} secondo Moor) talvolta non vanno a danneggiare l’utente, ma, al contrario, vanno a semplificare l’utilizzo del software o la lettura degli output.